{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-antarctica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6.079145\n",
      "Learning rate after iteration 0: 0.000200\n",
      "Cost after iteration 1000: 2.093383\n",
      "Learning rate after iteration 1000: 0.000200\n",
      "Cost after iteration 2000: 1.514726\n",
      "Learning rate after iteration 2000: 0.000200\n",
      "Cost after iteration 3000: 1.252565\n",
      "Learning rate after iteration 3000: 0.000200\n",
      "Cost after iteration 4000: 1.124956\n",
      "Learning rate after iteration 4000: 0.000200\n",
      "Cost after iteration 5000: 1.044192\n",
      "Learning rate after iteration 5000: 0.000200\n",
      "Cost after iteration 6000: 0.984784\n",
      "Learning rate after iteration 6000: 0.000200\n",
      "Cost after iteration 7000: 0.936639\n",
      "Learning rate after iteration 7000: 0.000200\n",
      "Cost after iteration 8000: 0.895089\n",
      "Learning rate after iteration 8000: 0.000200\n",
      "Cost after iteration 9000: 0.857767\n",
      "Learning rate after iteration 9000: 0.000200\n",
      "Cost after iteration 10000: 0.823545\n",
      "Learning rate after iteration 10000: 0.000200\n",
      "Cost after iteration 11000: 0.792231\n",
      "Learning rate after iteration 11000: 0.000200\n",
      "Cost after iteration 12000: 0.764093\n",
      "Learning rate after iteration 12000: 0.000200\n",
      "Cost after iteration 13000: 0.739116\n",
      "Learning rate after iteration 13000: 0.000200\n",
      "Cost after iteration 14000: 0.716922\n",
      "Learning rate after iteration 14000: 0.000200\n",
      "Cost after iteration 15000: 0.697064\n",
      "Learning rate after iteration 15000: 0.000200\n",
      "Cost after iteration 16000: 0.679171\n",
      "Learning rate after iteration 16000: 0.000200\n",
      "Cost after iteration 17000: 0.662955\n",
      "Learning rate after iteration 17000: 0.000200\n",
      "Cost after iteration 18000: 0.648198\n",
      "Learning rate after iteration 18000: 0.000200\n",
      "Cost after iteration 19000: 0.634724\n",
      "Learning rate after iteration 19000: 0.000200\n",
      "Cost after iteration 20000: 0.622387\n",
      "Learning rate after iteration 20000: 0.000200\n",
      "Cost after iteration 21000: 0.611326\n",
      "Learning rate after iteration 21000: 0.000190\n",
      "Cost after iteration 22000: 0.601585\n",
      "Learning rate after iteration 22000: 0.000182\n",
      "Cost after iteration 23000: 0.592939\n",
      "Learning rate after iteration 23000: 0.000174\n",
      "Cost after iteration 24000: 0.585212\n",
      "Learning rate after iteration 24000: 0.000167\n",
      "Cost after iteration 25000: 0.578260\n",
      "Learning rate after iteration 25000: 0.000160\n",
      "Cost after iteration 26000: 0.571972\n",
      "Learning rate after iteration 26000: 0.000154\n",
      "Cost after iteration 27000: 0.566254\n",
      "Learning rate after iteration 27000: 0.000148\n",
      "Cost after iteration 28000: 0.561029\n",
      "Learning rate after iteration 28000: 0.000143\n",
      "Cost after iteration 29000: 0.556235\n",
      "Learning rate after iteration 29000: 0.000138\n",
      "Cost after iteration 30000: 0.551819\n",
      "Learning rate after iteration 30000: 0.000133\n",
      "Cost after iteration 31000: 0.547736\n",
      "Learning rate after iteration 31000: 0.000129\n",
      "Cost after iteration 32000: 0.543949\n",
      "Learning rate after iteration 32000: 0.000125\n",
      "Cost after iteration 33000: 0.540424\n",
      "Learning rate after iteration 33000: 0.000121\n",
      "Cost after iteration 34000: 0.537136\n",
      "Learning rate after iteration 34000: 0.000118\n",
      "Cost after iteration 35000: 0.534059\n",
      "Learning rate after iteration 35000: 0.000114\n",
      "Cost after iteration 36000: 0.531174\n",
      "Learning rate after iteration 36000: 0.000111\n",
      "Cost after iteration 37000: 0.528461\n",
      "Learning rate after iteration 37000: 0.000108\n",
      "Cost after iteration 38000: 0.525905\n",
      "Learning rate after iteration 38000: 0.000105\n",
      "Cost after iteration 39000: 0.523493\n",
      "Learning rate after iteration 39000: 0.000103\n",
      "Cost after iteration 40000: 0.521211\n",
      "Learning rate after iteration 40000: 0.000100\n",
      "Cost after iteration 41000: 0.519050\n",
      "Learning rate after iteration 41000: 0.000098\n",
      "Cost after iteration 42000: 0.516998\n",
      "Learning rate after iteration 42000: 0.000095\n",
      "Cost after iteration 43000: 0.515048\n",
      "Learning rate after iteration 43000: 0.000093\n",
      "Cost after iteration 44000: 0.513192\n",
      "Learning rate after iteration 44000: 0.000091\n",
      "Cost after iteration 45000: 0.511422\n",
      "Learning rate after iteration 45000: 0.000089\n",
      "Cost after iteration 46000: 0.509733\n",
      "Learning rate after iteration 46000: 0.000087\n",
      "Cost after iteration 47000: 0.508119\n",
      "Learning rate after iteration 47000: 0.000085\n",
      "Cost after iteration 48000: 0.506574\n",
      "Learning rate after iteration 48000: 0.000083\n",
      "Cost after iteration 49000: 0.505094\n",
      "Learning rate after iteration 49000: 0.000082\n",
      "weight= \n",
      "{'W1': array([[-5.72953873e-02, -5.61949815e-02, -3.75797143e-02,\n",
      "         4.10819757e-02, -7.90764610e-02, -6.97170419e-02,\n",
      "        -5.63915675e-02, -7.37413134e-02, -7.16774443e-02,\n",
      "        -7.02305462e-02, -5.57968052e-02, -3.75285070e-02,\n",
      "        -6.18816542e-02, -1.01242012e-01, -5.57898489e-02,\n",
      "        -6.71631556e-02, -6.13993264e-02, -4.94383260e-02,\n",
      "        -6.86519066e-02, -6.10938067e-02, -6.46869523e-02,\n",
      "        -6.10617083e-02, -3.43719273e-02, -3.27487416e-01,\n",
      "        -6.45482890e-02, -6.40455157e-02, -6.82649605e-02,\n",
      "        -7.32539970e-02, -7.53849815e-02, -6.27133584e-02],\n",
      "       [ 4.07620170e-02,  5.80794672e-02, -1.03490419e-02,\n",
      "         4.38892223e-02,  5.27456848e-02,  6.26644813e-02,\n",
      "         5.41336715e-02,  4.06795289e-02,  4.89753192e-02,\n",
      "         5.44837653e-02,  4.58949493e-02,  5.56878594e-02,\n",
      "         2.98359735e-02,  7.54127891e-02,  6.37847773e-02,\n",
      "         4.57407157e-02,  5.52067125e-02,  4.95884748e-02,\n",
      "         4.08047685e-02,  4.99886763e-02,  5.35408535e-02,\n",
      "         2.77188084e-02,  1.05009253e-02,  1.32548102e-01,\n",
      "         5.33482283e-02,  6.17922165e-02,  4.27104634e-02,\n",
      "         5.41831367e-02,  5.10636477e-02,  3.04607834e-02],\n",
      "       [-5.07129414e-02, -5.12882648e-02, -1.68487815e-02,\n",
      "         1.61260722e-03, -7.36680670e-02, -5.29563038e-02,\n",
      "        -6.03107987e-02, -6.77950588e-02, -4.79880284e-02,\n",
      "        -4.59070975e-02, -5.99817811e-02, -4.42994168e-02,\n",
      "        -5.84112476e-02, -8.25314194e-02, -6.42800142e-02,\n",
      "        -3.74704396e-02, -7.99169860e-02, -5.42151546e-02,\n",
      "        -4.63358548e-02, -7.36304085e-02, -5.12906537e-02,\n",
      "        -5.52716005e-02, -2.96544267e-02, -3.34614838e-01,\n",
      "        -5.73257949e-02, -6.76573553e-02, -4.03406409e-02,\n",
      "        -4.13157885e-02, -5.79370939e-02, -4.97908883e-02],\n",
      "       [-4.04191890e-02, -4.37891957e-02, -1.71093239e-02,\n",
      "        -2.38252853e-02, -6.75909187e-02, -3.99719366e-02,\n",
      "        -4.66995887e-02, -5.25231591e-02, -3.84505235e-02,\n",
      "        -7.36377408e-02, -3.88192946e-02, -4.59303784e-02,\n",
      "        -6.32475611e-02, -8.06234699e-02, -5.32707757e-02,\n",
      "        -2.44044684e-02, -3.19134661e-02, -4.58321288e-02,\n",
      "        -5.74180474e-02, -5.60668525e-02, -5.08246239e-02,\n",
      "        -6.09901131e-02, -5.31495971e-02, -4.35054190e-01,\n",
      "        -5.30027344e-02, -5.60025059e-02, -5.80442762e-02,\n",
      "        -5.97517086e-02, -2.47914633e-02, -6.49807496e-02],\n",
      "       [ 4.77781406e-02,  5.46567527e-02, -1.26509437e-02,\n",
      "        -3.49720094e-01,  7.83638670e-02,  8.30166925e-02,\n",
      "         7.79497677e-02,  6.05177922e-02,  8.13680910e-02,\n",
      "         5.27539672e-02,  6.90206719e-02,  6.39919081e-02,\n",
      "         5.76681443e-02,  5.58978035e-02,  6.86354534e-02,\n",
      "         8.06493421e-02,  5.56179704e-02,  7.89292444e-02,\n",
      "         7.54314343e-02,  7.17376504e-02,  4.26485119e-02,\n",
      "         4.17775720e-02, -3.32674624e-02, -4.52666570e-01,\n",
      "         1.03131524e-01,  7.99992068e-02,  8.82351688e-02,\n",
      "         6.61188559e-02,  7.71349825e-02,  7.73588237e-02],\n",
      "       [ 2.48490671e-02,  1.39204368e-02, -4.08240905e-03,\n",
      "        -1.08203338e-01,  2.85159912e-02,  2.66290377e-02,\n",
      "         3.35736973e-02,  1.96899639e-02,  3.97941860e-02,\n",
      "         1.79548919e-02,  9.75405600e-03,  3.12033976e-02,\n",
      "         1.66768749e-02, -6.89216158e-04,  2.37034389e-02,\n",
      "         3.00074376e-02,  2.48521379e-02,  2.74274887e-02,\n",
      "         6.35352111e-02,  3.06680211e-02,  3.32159420e-02,\n",
      "        -9.90007835e-03, -5.09002357e-03, -1.53764379e-01,\n",
      "         1.87459184e-02,  1.35026448e-02,  2.62071603e-02,\n",
      "         1.92461977e-02,  1.63695652e-02,  3.39071190e-02],\n",
      "       [ 1.02790367e-02, -2.45483047e-03, -1.31783122e-02,\n",
      "        -8.66626814e-02,  5.85219333e-03,  3.81966479e-03,\n",
      "        -1.70486677e-02, -5.84932445e-03,  1.14071082e-03,\n",
      "         3.78777990e-03,  7.06034842e-03,  5.04832286e-03,\n",
      "        -1.46615003e-02, -2.42050954e-02, -1.46462505e-02,\n",
      "         1.56025715e-02, -6.41717649e-04,  3.09663375e-03,\n",
      "         7.89698317e-03, -5.72212469e-03, -1.57667394e-02,\n",
      "        -1.23555640e-02, -1.88411198e-02, -2.08727182e-01,\n",
      "         6.23960919e-03, -1.34986150e-02,  3.95520531e-03,\n",
      "         4.84073105e-03, -1.31115012e-02, -3.53536543e-03],\n",
      "       [ 4.24470903e-02,  5.84907814e-02,  1.25043030e-02,\n",
      "        -3.69635176e-02,  6.29154978e-02,  7.23825037e-02,\n",
      "         6.45412228e-02,  7.30212685e-02,  7.53448747e-02,\n",
      "         6.15101473e-02,  6.68066606e-02,  9.00959202e-02,\n",
      "         7.09097321e-02,  7.71997366e-02,  7.05788572e-02,\n",
      "         5.65869073e-02,  8.12984937e-02,  7.36808226e-02,\n",
      "         8.08186179e-02,  7.90007659e-02,  6.58552484e-02,\n",
      "         6.25852253e-02,  2.48243570e-02,  1.60592247e-01,\n",
      "         5.96436610e-02,  6.55997195e-02,  4.51458172e-02,\n",
      "         8.82996559e-02,  5.26406655e-02,  6.91511525e-02],\n",
      "       [ 5.34755414e-03, -4.74219032e-03,  7.36155633e-03,\n",
      "         4.51789964e-02,  1.89629565e-02,  2.60677161e-02,\n",
      "         1.44187985e-02,  2.43862693e-02,  2.56665724e-02,\n",
      "         1.72183171e-02,  1.77435133e-02,  2.55119414e-02,\n",
      "         2.10982025e-02,  2.96040657e-02, -3.15780197e-03,\n",
      "         2.11685862e-02,  2.43476172e-02,  1.92322807e-02,\n",
      "         2.39405636e-02,  3.96315115e-02,  1.96285121e-02,\n",
      "         2.07828568e-02,  1.36378906e-03,  1.04615804e-01,\n",
      "         1.57506643e-02,  1.03776223e-02,  2.05279470e-02,\n",
      "         1.12567907e-02,  1.87606341e-02,  6.19199366e-03],\n",
      "       [ 4.70538232e-02,  4.83571506e-02, -2.07325243e-02,\n",
      "        -3.90214550e-01,  7.09763637e-02,  7.36044795e-02,\n",
      "         8.76152931e-02,  9.08788615e-02,  8.42461695e-02,\n",
      "         7.35367170e-02,  9.18412604e-02,  6.02516517e-02,\n",
      "         5.45747843e-02,  5.77275430e-02,  7.71806129e-02,\n",
      "         7.57907388e-02,  7.75003597e-02,  6.07949826e-02,\n",
      "         6.56181261e-02,  8.95480488e-02,  7.25926167e-02,\n",
      "         4.12317491e-02,  7.81840996e-05, -4.78434716e-01,\n",
      "         7.13415870e-02,  7.99294598e-02,  6.50755620e-02,\n",
      "         7.22579714e-02,  7.51474481e-02,  7.31574530e-02],\n",
      "       [ 2.01153446e-02,  1.50052070e-02, -5.35235183e-03,\n",
      "         3.59648310e-02,  1.43209133e-02,  1.18578518e-02,\n",
      "         4.66313236e-03,  1.67900916e-02,  2.07018269e-02,\n",
      "         6.21389436e-03,  2.04233640e-02, -3.98066819e-03,\n",
      "        -3.61579321e-03,  2.28650890e-02,  4.19255925e-03,\n",
      "         2.56520993e-03,  9.89988166e-03,  5.76440348e-03,\n",
      "         1.58052077e-02, -2.01493618e-03,  7.78838055e-03,\n",
      "         3.95078843e-02,  7.29345665e-03,  6.23501486e-02,\n",
      "         1.85106205e-02,  1.80016309e-02,  2.63599520e-02,\n",
      "         1.40198513e-02,  5.94697653e-03,  2.66093642e-02],\n",
      "       [ 6.88935334e-04, -2.93439609e-02,  1.92736423e-03,\n",
      "        -2.89792489e-02,  3.89501686e-03, -1.10196624e-02,\n",
      "         5.30566474e-04, -5.31125005e-03, -1.36059108e-03,\n",
      "        -7.40358983e-03, -1.14903658e-02, -6.71853353e-03,\n",
      "        -2.05438852e-03, -2.03900624e-02,  8.95545384e-03,\n",
      "        -2.95771282e-03, -8.65951832e-04,  1.38216892e-02,\n",
      "        -6.53740147e-03, -1.84089903e-03, -1.41707559e-02,\n",
      "        -1.53299691e-02, -1.87192325e-03, -2.01108319e-01,\n",
      "         7.27550178e-03, -1.81806335e-02, -2.16309395e-02,\n",
      "        -4.24082492e-03, -2.09989189e-02,  1.94757552e-02],\n",
      "       [ 5.18964590e-02,  2.11300659e-02,  1.13488003e-02,\n",
      "         2.62831663e-02,  4.86857018e-02,  4.39844471e-02,\n",
      "         5.39303050e-02,  5.92867716e-02,  4.22561955e-02,\n",
      "         3.28085329e-02,  5.01546521e-02,  4.19623786e-02,\n",
      "         5.56400586e-02,  5.18979708e-02,  5.28794219e-02,\n",
      "         4.79361185e-02,  4.26822357e-02,  4.00897834e-02,\n",
      "         5.17066905e-02,  6.98821167e-02,  4.81304029e-02,\n",
      "         2.93677616e-02,  2.23798216e-02,  1.35000011e-01,\n",
      "         3.16964470e-02,  4.76556818e-02,  6.00992268e-02,\n",
      "         4.14377100e-02,  3.31620223e-02,  4.94186055e-02],\n",
      "       [ 6.16271596e-02,  4.69171461e-02,  2.25991524e-02,\n",
      "         3.29708976e-02,  6.55233394e-02,  5.64839536e-02,\n",
      "         4.73246318e-02,  5.07745686e-02,  4.82180181e-02,\n",
      "         5.78113491e-02,  4.04865711e-02,  6.37891229e-02,\n",
      "         5.04386574e-02,  5.55171624e-02,  5.75247327e-02,\n",
      "         2.86178516e-02,  4.10198538e-02,  4.27971729e-02,\n",
      "         5.75675453e-02,  4.44846021e-02,  5.79952236e-02,\n",
      "         3.01882997e-02,  2.05476636e-02,  1.18726525e-01,\n",
      "         6.08476565e-02,  4.68214661e-02,  5.46226660e-02,\n",
      "         4.44632979e-02,  3.83383333e-02,  4.70135823e-02],\n",
      "       [ 8.92900882e-02,  5.78610276e-02, -1.84194218e-02,\n",
      "        -3.41877606e-01,  1.01247556e-01,  8.29242627e-02,\n",
      "         8.81112287e-02,  9.54084250e-02,  9.00106060e-02,\n",
      "         9.63500871e-02,  1.05148549e-01,  9.18199243e-02,\n",
      "         9.06607590e-02,  8.75927457e-02,  9.29470756e-02,\n",
      "         8.40154929e-02,  8.33909536e-02,  8.24097612e-02,\n",
      "         1.12668622e-01,  9.31169419e-02,  8.32540254e-02,\n",
      "         6.79359190e-02, -1.86780573e-02, -3.39421418e-01,\n",
      "         8.77488548e-02,  7.25155357e-02,  9.12980913e-02,\n",
      "         8.27679170e-02,  8.98137480e-02,  9.68901441e-02],\n",
      "       [ 1.17507544e-01,  8.36937877e-02,  2.51343239e-02,\n",
      "        -1.86501970e-02,  1.10279550e-01,  1.06997087e-01,\n",
      "         9.79071371e-02,  9.90629595e-02,  1.06468066e-01,\n",
      "         9.68364342e-02,  1.01939646e-01,  9.41006679e-02,\n",
      "         1.19863468e-01,  1.23516947e-01,  1.27542619e-01,\n",
      "         1.02725448e-01,  9.79808042e-02,  9.67024471e-02,\n",
      "         1.16297677e-01,  1.18795592e-01,  8.85398071e-02,\n",
      "         9.06536987e-02,  4.25335309e-02,  3.44828583e-01,\n",
      "         1.09911176e-01,  1.16505620e-01,  8.99178347e-02,\n",
      "         8.64090786e-02,  1.10354726e-01,  1.07744656e-01],\n",
      "       [-3.05488485e-03, -3.24229502e-02, -2.05957334e-02,\n",
      "        -5.78407638e-02, -2.36252809e-02, -6.97996716e-03,\n",
      "        -1.86215085e-02, -1.46318621e-02, -2.43108164e-02,\n",
      "         1.35166531e-03, -2.97306242e-02, -2.26447716e-02,\n",
      "        -2.10629243e-02, -2.13345881e-02, -7.51539150e-03,\n",
      "        -3.73518901e-03, -1.07115603e-02, -8.15270797e-03,\n",
      "        -5.56908368e-03,  4.95484903e-03, -9.59679122e-03,\n",
      "        -3.51754432e-02, -1.53986803e-02, -3.03531976e-01,\n",
      "        -2.16247917e-02, -1.26682439e-02, -2.08519652e-02,\n",
      "         1.02115315e-02, -1.40725675e-02, -3.05622850e-02],\n",
      "       [ 1.00882137e-01,  8.12353283e-02,  3.86383908e-02,\n",
      "        -3.65504753e-02,  9.43995244e-02,  1.07325723e-01,\n",
      "         1.01598449e-01,  1.04818194e-01,  1.05624453e-01,\n",
      "         9.21235448e-02,  1.14207971e-01,  1.01459001e-01,\n",
      "         1.03032294e-01,  1.45346331e-01,  1.31275064e-01,\n",
      "         1.06015437e-01,  1.30425313e-01,  9.17494081e-02,\n",
      "         1.17911300e-01,  1.06492588e-01,  9.89342554e-02,\n",
      "         7.66033858e-02,  3.31257740e-02,  2.82713203e-01,\n",
      "         1.08690740e-01,  1.16643957e-01,  1.35998483e-01,\n",
      "         1.06088262e-01,  1.10472314e-01,  9.47277893e-02],\n",
      "       [ 3.48104222e-02,  6.59345021e-02, -2.31444076e-02,\n",
      "        -3.74874350e-01,  7.30406025e-02,  8.19553082e-02,\n",
      "         7.60393904e-02,  9.15758972e-02,  7.09040195e-02,\n",
      "         5.45776876e-02,  7.40011940e-02,  7.25720429e-02,\n",
      "         6.24529624e-02,  4.81628149e-02,  6.70637510e-02,\n",
      "         9.02547149e-02,  6.67735150e-02,  5.89911879e-02,\n",
      "         7.57053699e-02,  5.47100640e-02,  6.30571362e-02,\n",
      "         4.97778420e-02, -2.71442451e-02, -4.55830264e-01,\n",
      "         6.67830841e-02,  8.88879118e-02,  7.67070055e-02,\n",
      "         6.08266878e-02,  6.01457713e-02,  7.20653655e-02],\n",
      "       [ 1.24896096e-02,  1.69963126e-03,  8.45310601e-03,\n",
      "         3.84573364e-02,  2.46819407e-02,  1.82870784e-02,\n",
      "         1.29913018e-02,  1.52909665e-02,  5.06490924e-03,\n",
      "         2.27681527e-02,  1.77408332e-02,  9.38988520e-03,\n",
      "         1.48947311e-02,  1.22183250e-02,  3.88077468e-02,\n",
      "         9.41686599e-03,  1.91168834e-02,  1.75802018e-02,\n",
      "         5.94842671e-03,  1.39935693e-02,  9.30341775e-03,\n",
      "         9.99452030e-03,  7.11363288e-03,  6.89139830e-02,\n",
      "         2.17318374e-02,  9.79187722e-03,  8.61918960e-03,\n",
      "         8.02195289e-03,  5.23348907e-03, -3.51591139e-03]]), 'b1': array([[ 0.44451049],\n",
      "       [ 0.73842087],\n",
      "       [ 0.63713257],\n",
      "       [ 1.13723814],\n",
      "       [-0.00688849],\n",
      "       [ 0.38565327],\n",
      "       [ 0.81057584],\n",
      "       [ 0.73102235],\n",
      "       [ 0.37374533],\n",
      "       [ 0.18500847],\n",
      "       [ 0.89438374],\n",
      "       [ 0.45875998],\n",
      "       [ 0.27586676],\n",
      "       [ 0.77088427],\n",
      "       [ 0.15149056],\n",
      "       [-0.27437825],\n",
      "       [ 0.98023637],\n",
      "       [ 0.0868957 ],\n",
      "       [ 0.09148689],\n",
      "       [ 0.84925001]]), 'W2': array([[-0.3928635 ,  0.83763647, -0.4116644 , -0.63654019,  1.05800089,\n",
      "         0.25184929, -0.15204654,  0.87989821,  0.31618973,  1.00399443,\n",
      "         0.28249739,  0.05305155,  0.51984422,  0.79714065,  0.94651961,\n",
      "         1.07609425, -0.09689384,  1.0696365 ,  1.0114594 ,  0.38298671],\n",
      "       [ 0.94230278,  0.87768201,  0.93740931,  0.98783451,  0.31716193,\n",
      "         0.692143  ,  0.38525839,  0.11131511,  0.24020648,  0.38497833,\n",
      "         0.38624671,  0.85845012,  0.36914773,  0.50980257,  0.25201991,\n",
      "        -0.13650669,  0.93032848,  0.06626723,  0.40389544,  0.62763261]]), 'b2': array([[0.36842416],\n",
      "       [0.49934872]])}\n",
      "On training set:\n",
      "True Positive:   138\n",
      "True Negative:   278\n",
      "False Negative:   31\n",
      "False Positive:   8\n",
      "True Positive Rate / Recall: 81.66%\n",
      "Precision: 94.52%\n",
      "False Positive Rate / Fallout: 2.80%\n",
      "On Test set:\n",
      "True Positive:   37\n",
      "True Negative:   71\n",
      "False Negative:   6\n",
      "False Positive:   0\n",
      "True Positive Rate / Recall: 86.05%\n",
      "Precision: 100.00%\n",
      "False Positive Rate / Fallout: 0.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    breast_cancer = datasets.load_breast_cancer()\n",
    "    X = np.array(breast_cancer.data)  \n",
    "    y = np.array(breast_cancer.target)\n",
    "\n",
    "   \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_mean=np.mean(X_train)\n",
    "    X_std=np.std(X_train)\n",
    "\n",
    "    X_valid=(X_valid-X_mean)/X_std\n",
    " \n",
    "    X_train = (X_train-X_mean)/X_std\n",
    "    y_train = one_hot_vector(y_train)\n",
    "    y_valid = one_hot_vector(y_valid)\n",
    "\n",
    "    d = model(X_train.T, y_train.T,X_valid.T, y_valid.T, n_h=20, num_iters=50000, alpha=0.0002, print_cost=True)\n",
    "\n",
    "def one_hot_vector(y):\n",
    "    out = np.zeros((y.shape[0], max(y)+1))\n",
    "    for i in range(y.shape[0]):\n",
    "        out[i, y[i]] = 1\n",
    "    return out\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "\n",
    "def layers(X, Y):\n",
    "    \"\"\"\n",
    "\n",
    "    :param X:\n",
    "    :param Y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_x = X.shape[0]\n",
    "    n_y = Y.shape[0]\n",
    "    return n_x, n_y\n",
    "\n",
    "\n",
    "def initialize(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "\n",
    "    :param n_x:\n",
    "    :param n_h:\n",
    "    :param n_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.random.rand(n_h, 1)\n",
    "    W2 = np.random.rand(n_y, n_h)\n",
    "    b2 = np.random.rand(n_y, 1)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def forward_prop(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "\n",
    "    return A2, cache\n",
    "\n",
    "\n",
    "def compute_cost(A2, Y, parameters):\n",
    "    m = Y.shape[1]\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), (1 - Y))\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def back_prop(parameters, cache, X, Y):\n",
    "    m = Y.shape[1]\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.square(A1))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_params(parameters, grads, alpha):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def model(X, Y,X_valid, y_valid, n_h, num_iters, alpha, print_cost):\n",
    "    np.random.seed(3)\n",
    "    n_x = layers(X, Y)[0]\n",
    "    n_y = layers(X, Y)[1]\n",
    "\n",
    "    parameters = initialize(n_x, n_h, n_y)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    costs = []\n",
    "    for i in range(0, num_iters):\n",
    "\n",
    "        A2, cache = forward_prop(X, parameters)\n",
    "\n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    "        grads = back_prop(parameters, cache, X, Y)\n",
    "        if (i > 20000):\n",
    "            alpha1 = (20000 / i) * alpha\n",
    "            parameters = update_params(parameters, grads, alpha1)\n",
    "        else:\n",
    "            parameters = update_params(parameters, grads, alpha)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "            if i <= 20000:\n",
    "                print(\"Learning rate after iteration %i: %f\" % (i, alpha))\n",
    "            else:\n",
    "                print(\"Learning rate after iteration %i: %f\" % (i, alpha1))\n",
    "\n",
    "\n",
    "    print('weight= ')\n",
    "    print(parameters)\n",
    "    predictions = predict(parameters, X)\n",
    "#     print('Accuracy on training set: %.2f' % float(\n",
    "#         (np.dot(Y, predictions.T) + np.dot(1 - Y, 1 - predictions.T)) / float(Y.size) * 100) + '%')\n",
    "    truePositive = 0\n",
    "    trueNegative = 0\n",
    "    falseNegative = 0\n",
    "    falsePositive = 0\n",
    "    predList = predictions.tolist()\n",
    "    tlist = Y.tolist()\n",
    "\n",
    "    array_length = len(predList[0])\n",
    "    for i in range(array_length):\n",
    "        if predList[0][i] == 1 and tlist[0][i] == 1:\n",
    "            truePositive += 1\n",
    "        elif predList[0][i] == 0 and tlist[0][i] == 0:\n",
    "            trueNegative += 1\n",
    "        elif predList[0][i] == 0 and tlist[0][i] == 1:\n",
    "            falseNegative += 1\n",
    "        elif predList[0][i] == 1 and tlist[0][i] == 0 :\n",
    "            falsePositive += 1\n",
    "        else:\n",
    "            print(predList[0][i])\n",
    "            print(tlist[0][i])\n",
    "            print(\"WTF\")\n",
    "    tpr = truePositive / (truePositive + falseNegative) * 100\n",
    "    fpr = falsePositive / (falsePositive + trueNegative) * 100\n",
    "    precision = truePositive / (truePositive + falsePositive) * 100\n",
    "    print(\"On training set:\\nTrue Positive:  \", truePositive)\n",
    "    print(\"True Negative:  \", trueNegative)\n",
    "    print(\"False Negative:  \", falseNegative)\n",
    "    print(\"False Positive:  \", falsePositive)\n",
    "    print(\"True Positive Rate / Recall: %.2f\" % tpr+str('%'))\n",
    "    print(\"Precision: %.2f\" %precision+str('%'))\n",
    "    print(\"False Positive Rate / Fallout: %.2f\" %fpr+str('%'))\n",
    "\n",
    "    predictions = predict(parameters, X_valid)\n",
    "#     print('Accuracy on test set: %.2f' % float(\n",
    "#         (np.dot(Y_test, predictions.T) + np.dot(1 - Y_test, 1 - predictions.T)) / float(Y_test.size) * 100) + '%')\n",
    "    truePositive = 0\n",
    "    trueNegative = 0\n",
    "    falseNegative = 0\n",
    "    falsePositive = 0\n",
    "    predList = predictions.tolist()\n",
    "    tlist = y_valid.tolist()\n",
    "\n",
    "    assert (len(predictions[0])== len(tlist[0]))\n",
    "    array_length = len(predList[0])\n",
    "    for i in range(array_length):\n",
    "        if predList[0][i] == 1 and tlist[0][i] == 1:\n",
    "            truePositive += 1\n",
    "        elif predList[0][i] == 0 and tlist[0][i] == 0:\n",
    "            trueNegative += 1\n",
    "        elif predList[0][i] == 0 and tlist[0][i] == 1:\n",
    "            falseNegative += 1\n",
    "        elif predList[0][i] == 1 and tlist[0][i] == 0 :\n",
    "            falsePositive += 1\n",
    "        else:\n",
    "            print(predList[0][i])\n",
    "            print(tlist[0][i])\n",
    "            print(\"WTF\")\n",
    "    tpr = truePositive / (truePositive + falseNegative) * 100\n",
    "    fpr = falsePositive / (falsePositive + trueNegative) * 100\n",
    "    precision = truePositive / (truePositive + falsePositive) * 100\n",
    "    print(\"On Test set:\\nTrue Positive:  \", truePositive)\n",
    "    print(\"True Negative:  \", trueNegative)\n",
    "    print(\"False Negative:  \", falseNegative)\n",
    "    print(\"False Positive:  \", falsePositive)\n",
    "    print(\"True Positive Rate / Recall: %.2f\" % tpr+str('%'))\n",
    "    print(\"Precision: %.2f\" %precision+str('%'))\n",
    "    print(\"False Positive Rate / Fallout: %.2f\" %fpr+str('%'))\n",
    "\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(alpha))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def predict(parameters, X):\n",
    "    A2, cache = forward_prop(X, parameters)\n",
    "    predictions = np.round(A2)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "geological-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X = np.array(breast_cancer.data)  \n",
    "y = np.array(breast_cancer.target)\n",
    "\n",
    "   \n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_mean=np.mean(X_train)\n",
    "X_std=np.std(X_train)\n",
    "\n",
    "X_valid=(X_valid-X_mean)/X_std\n",
    " \n",
    "X_train = (X_train-X_mean)/X_std\n",
    "y_train = one_hot_vector(y_train)\n",
    "y_valid = one_hot_vector(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-conversion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
